# 并发

### HashMap 并发下的死循环

死循环问题是指在并发环境下，因为多个线程同时进行 put 操作，导致链表形成环形数据结构，一旦形成环形数据结构，在 get(key) 的时候就会产生死循环。

**死循环原因**：

HashMap 导致死循环的原因是由以下条件共同导致的：

1. HashMap 使用头插法进行数据插入（JDK 1.8 之前）；
2. 多线程同时添加；
3. 触发了 HashMap 扩容。

当满足以上所有条件时，HashMap 就会出现死循环问题。



### 进程线程区别

1. 进程是系统分配资源的基本单位，线程是程序执行的基本单位；
2. 进程拥有独立的内存空间和资源，而线程则共享进程的内存和资源
3. 进程之间的通信比较复杂，而线程之间可以直接共享数据；
4. 进程的切换代价比较大，需要保存上下文和状态，而线程的切换代价比较小，因为它们共享进程的资源







### 线程通信方式

线程通讯的实现方式主要有以下两种：

**共享内存**：多个线程可以访问同一个共享内存区域，通过读取和写入内存中的数据来进行通讯和同步。 

**消息传递**：多个线程之间通过消息队列、管道、信号量等机制来传递信息和同步状态。



**线程通讯的实现方法 **有以下几种：

1. 等待和通知机制：使用 Object 类的 wait() 和 notify() 方法来实现线程之间的通讯。当一个线程需要等待另一个线程执行完某个操作时，它可以调用 wait() 方法使自己进入等待状态，同时释放占有的锁，等待其他线程调用 notify() 或 notifyAll() 方法来唤醒它。被唤醒的线程会重新尝试获取锁并继续执行。
2. 信号量机制：使用 Java 中的 Semaphore 类来实现线程之间的同步和互斥。Semaphore 是一个计数器，用来控制同时访问某个资源的线程数。当某个线程需要访问共享资源时，它必须先从 Semaphore 中获取一个许可证，如果已经没有许可证可用，线程就会被阻塞，直到其他线程释放了许可证。
3. 栅栏机制：使用 Java 中的 CyclicBarrier 类来实现多个线程之间的同步，它允许多个线程在指定的屏障处等待，并在所有线程都达到屏障时继续执行。
4. 锁机制：使用 Java 中的 Lock 接口和 Condition 接口来实现线程之间的同步和互斥。Lock 是一种更高级的互斥机制，它允许多个条件变量（Condition）并支持在同一个锁上等待和唤醒









### volatile

volatile 是一种关键字，用于保证多线程情况下共享变量的可见性。当一个变量被声明为 volatile 时，每个线程在访问该变量时都会立即刷新其本地内存中该变量的值，确保所有线程都能读到最新的值。并且使用 volatile 可以禁止指令重排序，这样就能有效的预防，因为指令重排序而导致的线程安全问题。

**解决内存可见性问题**：

先说下 Java 内存模型，主要是用来屏蔽不同硬件和操作系统的内存访问差异的，因为在不同的硬件和不同的操作系统下，内存的访问是有一定的差异得，这种差异会导致相同的代码在不同的硬件和不同的操作系统下有着不一样的行为，而 Java 内存模型就是解决这个差异，统一相同代码在不同硬件和不同操作系统下的差异的。

Java 内存模型规定：所有的变量（实例变量和静态变量）都必须存储在主内存中，每个线程也会有自己的工作内存，线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行。线程不能直接读写主内存中的变量，然而，Java 内存模型会带来内存可见性问题，也就是当某个线程修改了主内存中共享变量的值之后，其他线程不能感知到此值被修改了，它会一直使用自己工作内存中的“旧值”，这样程序的执行结果就不符合我们的预期了，这就是内存可见性问题。

当线程读取一个 volatile 变量时，会从主内存中读取变量的最新值，并把它存储到线程的工作内存中。当线程写入一个 volatile 变量时，会把变量的值写入到线程的工作内存中，并强制将这个值刷新到主内存中。这样就保证了 volatile 变量的可见性和有序性。



使用**内存屏障** 解决 **指令重排序** 导致的 **多线程下程序错误问题**：

内存屏障是一种硬件机制，用于控制 CPU 缓存和主内存之间的数据同步。在 Java 中，内存屏障通常有两种：读屏障和写屏障。

在有内存屏障的地方，会禁止指令重排序，即屏障下面的代码不能跟屏障上面的代码交换执行顺序。在有内存屏障的地方，线程修改完共享变量以后会马上把该变量从本地内存写回到主内存，并且让其他线程本地内存中该变量副本失效（使用 MESI 协议）。

**MESI 协议**是一种缓存一致性协议，它是支持写回（write-back）缓存的最常用协议。MESI 协议基于总线嗅探机制实现了事务串形化，也用状态机机制降低了总线带宽压力，做到了 CPU 缓存一致性。MESI 协议这 4 个字母代表 4 个状态，分别是：Modified（已修改）、Exclusive（独占）、Shared（共享）、Invalidated（已失效）。







### synchronized 和 Lock 主要的区别

synchronized 和 Lock 主要的区别有以下几个方面：

1. 锁的获取方式：synchronized 是隐式获取锁的，即在进入 synchronized 代码块或方法时自动获取锁，退出时自动释放锁；而 Lock 需要程序显式地获取锁和释放锁，即需要调用 lock() 方法获取锁，调用 unlock() 方法释放锁。
2. 锁的性质：synchronized 是可重入的互斥锁，即同一个线程可以多次获得同一把锁，而且锁的释放也只能由获得锁的线程来释放；Lock 可以是可重入的互斥锁，也可以是非可重入的互斥锁，还可以是读写锁。
3. 锁的粒度：synchronized 是以代码块和方法为单位进行加锁和解锁，而 Lock 可以精确地控制锁的范围，可以支持多个条件变量。
4. 性能：在低并发的情况下，synchronized 的性能优于 Lock，因为 Lock 需要显式地获取和释放锁，而 synchronized 是在 JVM 层面实现的；在高并发的情况下，Lock 的性能可能优于 synchronized，因为 Lock 可以更好地支持高并发和读写分离的场景。

总的来说，synchronized 的使用更加简单，但是在某些场景下会受到性能的限制；而 Lock 则更加灵活，可以更精确地控制锁的范围和条件变量，但是使用起来比较繁琐。需要根据具体的业务场景和性能需求来选择使用哪种锁机制。



### Synchronized

这四种锁是指锁的状态，专门针对synchronized的。

首先介绍  **Java对象头、monitor** 的概念：

Hotspot 虚拟机的**对象头**主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。

**Mark Word**：存储对象的 HashCode，分代年龄和锁标志位信息。

**class Point**：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。



synchronized 的底层是通过 **Monitor**（监视器）实现的。

monitorenter：表示进入监视器；

monitorexit：表示退出监视器。

Monitor 底层是由 C++实现的，它的实现对象是 ObjectMonitor。

* _count：记录该线程获取锁的次数（也就是前前后后，这个线程一共获取此锁多少次）。

* _recursions：锁的重入次数。

* _owner：The Owner 拥有者，是持有该 ObjectMonitor（监视器）对象的线程；

* _EntryList：EntryList 监控集合，存放的是处于阻塞状态的线程队列，在多线程下，竞争失败的线程会进入 EntryList 队列。

* _WaitSet：WaitSet 待授权集合，存放的是处于 wait 状态的线程队列，当线程执行了 wait() 方法之后，会进入 WaitSet 队列。

监视器执行的流程是这样的：

1. 线程通过 CAS（对比并替换）尝试获取锁，如果获取成功，就将 _owner 字段设置为当前线程，说明当前线程已经持有锁，并将 _recursions 重入次数的属性 +1。如果获取失败则先通过自旋 CAS 尝试获取锁，如果还是失败则将当前线程放入到 EntryList 监控队列（阻塞）。
2. 当拥有锁的线程执行了 wait 方法之后，线程释放锁，将 owner 变量恢复为 null 状态，同时将该线程放入 WaitSet 待授权队列中等待被唤醒。
3. 当调用 notify 方法时，随机唤醒 WaitSet 队列中的某一个线程，当调用 notifyAll 时唤醒所有的 WaitSet 中的线程尝试获取锁。
4. 线程执行完释放了锁之后，会唤醒 EntryList 中的所有线程尝试获取锁。



但是，由于阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长，这就是 JDK 6之前 synchronized 效率低的原因。JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。



#### **锁升级**：

目前锁一共有4种状态，级别从低到高依次是：**无锁、偏向锁、轻量级锁和重量级锁**。锁状态只能升级不能降级。

先进行一个概括，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用 CAS 操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁呢，是将没有获取到锁的线程都阻塞。



然后我详细说一下这几个锁状态：

**无锁**：

无锁状态下，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。

无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。 CAS原理及应用即是无锁的实现。

**偏向锁**：

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。

引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁的执行，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。

**轻量级锁**：

当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。

在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。

拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明有多个线程竞争锁。

若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。

**重量级锁**：

升级为重量级锁时，锁标志的状态值变为 “10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。



### 乐观锁 悲观锁

乐观锁，悲观锁

对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。java 中 **synchronized 和 Lock 都是悲观锁**。

而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。

**乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法**，Java原子类中的递增操作就通过CAS自旋实现的。

- **悲观锁适合写操作多**的场景，先加锁可以保证写操作时数据正确。
- **乐观锁适合读操作多**的场景，不加锁的特点能够使其读操作的性能大幅提升。



### CAS

CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。

CAS算法涉及到三个操作数：

- 需要读写的内存值 V。
- 进行比较的值 A。
- 要写入的新值 B。

当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。

CAS虽然很高效，但是它也存在三大问题，这里也简单说一下：

1. **ABA问题**

   * CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。
   * 举例：余额200，取100块，可是由于程序问题，启动了两个线程 A B，A取钱成功后，又进行转账100块，余额还是200，这时B线程检查余额还是200，就继续进行扣减操作。预计只有一次扣减一次增加，余额不变，可是现在余额减少了100，就出现了错误。

   - JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。

2. **循环时间长开销大**。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。

3. 只能保证一个共享变量的原子操作

   * 对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

   - Java从1.5开始JDK提供了AtomicReference类来保证**引用对象之间的原子性**，**可以把多个变量放在一个对象里来进行CAS操作**。



### 公平锁 非公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。



例如 ReentrantLock 有公平和非公平的两种实现方式

ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。公平锁在 lock() 之前，先判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。而非公平锁就不需要判断，只要第一次 CAS 成功就能获取锁。



### 可重入锁 非可重入锁

可重入锁是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞

Java中 **ReentrantLock** 和 **synchronized** 都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。

ReentrantLock 继承父类AQS，其父类AQS中维护了一个同步状态status来标记锁有没有被占用，并且计数重入次数，status初始值为0。

当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。

释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。



### 独占锁 共享锁

在独占锁中 state 值通常是0或者1，在共享锁中state就是持有锁的数量

在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量。于是将state变量切分成了两个部分，高16位表示读锁个数，低16位表示写锁个数

tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取。

只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。



### AQS

AQS 的核心思想是利用一个双向队列来保存等待锁的线程，同时利用一个 state 变量来表示锁的状态。AQS 的同步器可以分为独占模式和共享模式两种。独占模式是指同一时刻只允许一个线程获取锁。

常见的实现类有 ReentrantLock；共享模式是指同一时刻允许多个线程同时获取锁，常见的实现类有 Semaphore、CountDownLatch、等。



AQS 中资源共享模式分为两种：

1. 独占模式：AQS 维护了一个同步队列，该队列中保存了所有等待获取锁的线程。当一个线程尝试获取锁时，如果锁已经被其他线程持有，则将该线程加入到同步队列的尾部，并挂起线程，等待锁被释放。当锁被释放时，从同步队列中取出一个线程，使其获取锁，同时将它从队列中移除，唤醒该线程继续执行。独占模式又分为公平锁和非公平锁： 
   1. 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁；
   2. 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的。
2. 共享模式：AQS 维护了一个等待队列和一个共享计数器。共享计数器表示当前允许获取锁的线程数，当一个线程尝试获取锁时，如果当前允许获取锁的线程数已经达到了最大值，则将该线程加入到等待队列中，并挂起线程，等待其他线程释放锁或者共享计数器增加。当锁被释放时，会从等待队列中取出一个线程，使其获取锁，同时将它从队列中移除，唤醒该线程继续执行。

AQS 提供了一些方法，允许我们在自定义同步器中使用 AQS 的同步机制。其中包括 acquire()、release()、tryAcquire()、tryRelease() 等方法，这些方法的具体实现会因同步器的不同而有所区别。









### 为什么 ThreadLocal Entry key 设置为弱引用？

为了**防止内存泄漏**。

每个线程Thread类都有个属性ThreadLocalMap，用来维护该线程的多个ThreadLocal变量，该Map是自定义实现的Entry[]数组结构，并非继承自原生Map类，Entry其中Key即是ThreadLocal变量本身，Value则是具体该线程中的变量副本值。

Entry 的 Key 即 ThreadLocal 对象是采用**弱引用**引入的，如果这个 key 只存在弱引用了，也就是只在当前线程的 ThreadLocalMap 中了，没人使用，那么就会被回收。

key 回收之后，只剩下强引用的 value，这时，如果再进行 get、remove、put 方法就会检测 key 为 null 的entry，并删除 value。

内存泄漏场景：忘记remove，后面再也没使用过 ThreadLocal 了



### ThreadLocal 的 hash 方式

使用了 斐波那契哈希 算法。

```java
// 1640531527
int HASH_INCREMENT = 0x61c88647;

// 黄金分割点：(√5 - 1) / 2 = 0.6180339887
// -1640531527
int p =BigDecimal.valueOf(Math.pow(2, 32) * 0.6180339887).intValue();
```



每次实例化一个 ThreadLocal 时候，都会调用 nextHashCode()，也就是将 static 的 AtomicInteger 对象 nextHashCode=nextHashCode + 0x61c88647；

![image-20230826232721195](./Java基础 JVM 并发 设计模式.assets/image-20230826232721195.png)

实验：

```java
int HASH_INCREMENT = 0x61c88647;
Set<Integer> set = new HashSet<>();
int hashCode = 0;
for (int i = 0; i < 2049; i++) {
    hashCode = i+HASH_INCREMENT;
    int idx = hashCode & 2047;
    if(set.contains(idx)){
        System.out.println("i="+i+" 哈希冲突："+idx);
    }else{
        set.add(idx);
    }
}
```

![image-20230826233112436](./Java基础 JVM 并发 设计模式.assets/image-20230826233112436.png)

可以看到，在容量满之前都是 0 冲突的，只要是顺序来的请求，斐波那契 hash 能做到 0 冲突。

