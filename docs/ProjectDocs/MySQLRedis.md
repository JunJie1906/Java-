# MySQL

## 一、架构

### 一条查询语句执行流程（MySQL架构）

- **连接器：** 登录 MySQL时候的身份认证和权限相关
- **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
- **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，经过词法分析和语法分析，检查你的 SQL 语句语法是否正确。
- **优化器：** 按照 MySQL 认为最优的方案去执行，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。
- **执行器：**根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。
- **存储引擎**：主要负责数据的存储和读取，支持 InnoDB、MyISAM、Memory 等多种存储引擎。



### 一条更新语句执行流程

当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。

具体更新一条记录 `UPDATE t_user SET name = '张三' WHERE id = 1;` 的流程如下:

1. 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：
   - 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
   - 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。
2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
   - 如果一样的话就不进行后续更新流程；
   - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，在内存修改该 Undo 页面后，需要记录对应的 redo log。
4. InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。
5. 此时，一条记录就更新完成了。
6. 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。
7. 事务提交，剩下的就是「两阶段提交」。



### MyISAM 和 InnoDB 有什么区别？

MySQL 5.5 版本之后，InnoDB 是 MySQL 的默认存储引擎。

行锁：InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。

事务：MyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别。

外键：MyISAM 不支持外键，而 InnoDB 支持。

MVCC：MyISAM 不支持 MVCC，而 InnoDB 支持。

索引：虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。

RedoLog：MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。

性能：InnoDB 的性能比 MyISAM 更强大。



### NULL 值是怎么存放的

MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。

NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。



### varchar(n) 实际占用数据的大小

MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。



### 为什么MySQL不建议使用 `NULL` 作为列默认值？

`NULL` 跟 `''`(空字符串)是两个完全不一样的值，区别如下：

- `NULL` 代表一个不确定的值,就算是两个 `NULL`,它俩也不一定相等。例如，`SELECT NULL=NULL`的结果为 false，但是在我们使用`DISTINCT`,`GROUP BY`,`ORDER BY`时,`NULL`又被认为是相等的。
- `''`的长度是 0，是不占用空间的，而`NULL` 是需要占用空间的。
- `NULL` 会影响聚合函数的结果。例如，`SUM`、`AVG`、`MIN`、`MAX` 等聚合函数会忽略 `NULL` 值。 `COUNT` 的处理方式取决于参数的类型。如果参数是 `*`(`COUNT(*)`)，则会统计所有的记录数，包括 `NULL` 值；如果参数是某个字段名(`COUNT(列名)`)，则会忽略 `NULL` 值，只统计非空值的个数。
- 查询 `NULL` 值时，必须使用 `IS NULL` 或 `IS NOT NULLl` 来判断，而不能使用 =、!=、 <、> 之类的比较运算符。而`''`是可以使用这些比较运算符的。



## 二、索引

### 索引的分类 

- 按「数据结构」分类：**B+tree索引、Hash索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。



#### 聚簇索引 非聚簇索引

从物理存储的角度来看，索引分为聚簇索引（主键索引）、二级索引

这两个区别就是：

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是**覆盖索引**。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。

#### 覆盖索引

在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是**覆盖索引**。

还有几次面试

#### 索引下推

MySQL 5.6 引入，在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。



### 什么时候需要建立索引

索引最大的好处是提高查询速度，但是索引也是有缺点的，比如：

- 需要占用物理空间，数量越大，占用空间越大；
- 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；
- 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。

所以，索引是根据场景来使用的。

#### 什么时候适用索引？

- 字段有唯一性限制的，比如唯一 id；
- 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。

#### 什么时候不需要创建索引？

- `WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
- 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- 表数据太少的时候，不需要创建索引；
- 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。







### （重要）慢查询如何优化？

1.先运行看看是否真的很慢，（注意把缓存关了）

2.explain查看执行计划，是否与1预期一致

3.如果order by limit 形式的sql语句，让排序的表优先查

4.了解业务方使用场景

5.加索引时参照建索引的几大原则：选择唯一性索引、为经常需要排序操作、分组操作的字段建立索引、为经常作为查询条件的字段建立索引、限制索引的数目、尽量使用数据量少的索引、最左前缀匹配原则，索引列不能参与计算、当单个索引字段查询数据很多，区分度都不是很大时，则需要考虑建立联合索引来提高查询效率。

尽量避免在 where 子句中使用!=或<>操作符，否则引擎将放弃使用索引而进行全表扫描。

应尽量避免在 where 子句中使用or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描。

in 和 not in 也要慎用，否则会导致全表扫描

用>=替代>，前者DBMS将直接跳到第一个DEPT等于4的记录，而后者将首先定位到DEPTNO=3的记录并且向前扫描到第一个DEPT大于3的记录。

用Where子句替换having子句。

尽量避免大事务操作，提高系统并发能力。

尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。

6.观察结果，不符合预期就继续分析

（我的理解是，在一个线上的业务中，如果出现慢查询，很少是因为索引的问题，因为写代码的时候一般都会注意这些索引优化的情况，比如覆盖索引、防止索引失效，另外提交代码之前都会进行代码的 Review，常见的索引问题基本不可能发生在线上，所以线上环境很少有单纯通过加索引来提升查询效率的，有些大表可能已经加了许多索引了，但还是很慢，如果再加就会造成整个表的更新效率降低，这些都属于是一个 trade-off 的问题，如果预算足够就继续分库分表。否则就需要进行大表拆分、表结构重新设计）



### （重要）慢查询例子

#### 1、区分度低的多个状态查询

```sql
select
   * 
from
   user
where
   user.status1=1 
   and (
      user.status2=0 
      or user.status2=2 
      or user.status2=4
   );
```

user表上有两个状态，需要根据这两个状态拿到相应的记录，但是这两个状态区分度很低，单独加索引没什么用，加了联合索引 (status1, status2)，就能解决。

#### 2、子查询改 Join 优化 

```sql
explain select *
from emp_org_allocation eoa
where start_date =
    (
      select max(start_date)
      from emp_org_allocation
      where emp_id = eoa.emp_id
        and status = 1
        and start_date  <= CURDATE()
    )
```

情景：有一个活动表，有用户 id，有活动开始时间，查询某个用户最近开始的一条活动数据。最开始的写法是用了嵌套子查询，where start_time=(select max(time) from table where xxx) and xxx

这里外层是没有走索引的。原因是子查询中使用了聚合函数 



改进后，使用自连接 + 条件判断的方式避免使用 max造成的索引失效情况：

```sql
SELECT *
FROM emp_org_allocation eoa
         LEFT JOIN emp_org_allocation eoa2
                   ON eoa.emp_id = eoa2.emp_id
                       AND eoa.tenant_id = eoa2.tenant_id
                       AND eoa.start_date < eoa2.start_date
                       AND eoa2.STATUS = 1
                       AND eoa2.start_date <= CURDATE()
WHERE eoa.STATUS = 1
  AND eoa.start_date <= CURDATE()
  AND eoa2.start_date is NULL
```



然后我说一下我比较熟悉的 sql 优化方法：

### （重要）优化索引的方法

#### 1、覆盖索引优化

覆盖索引是指 SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作。

（**由于在线上情况，一个表索引不能建太多，特别是对那种经常查询的大表，如果新建索引会极大增加数据插入删除的时间，不可能对每个业务都做覆盖索引，所以这种方式用的不多**）



#### 2、需要排序的字段最好是自增的

InnoDB 创建主键索引默认是 聚簇索引，数据被存放在了 B+Tree 的叶子节点上。也就是说，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中。

**如果我们使用自增主键**，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次**插入一条新记录，都是追加操作，不需要重新移动数据**，因此这种插入数据的方法效率非常高。

**如果我们使用非自增主键**，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为**页分裂**。**页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率**。



#### 3、防止索引失效

发生索引失效的情况：

- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对索引列做了聚合计算、函数、类型转换操作，这些情况下都会造成索引失效；
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

我上面说的是常见的索引失效场景，实际过程中，可能会出现其他的索引失效场景，这时我们就需要查看执行计划，通过执行计划显示的数据判断查询语句是否使用了索引。



### explain 语句 

对于explain生成的执行计划，参数有：

- possible_keys 字段表示可能用到的索引；
- key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；
- key_len 表示索引的长度；
- **rows** 表示扫描的数据行数。
- **type** 表示数据扫描类型，我们需要重点看这个。
- **extra** 

> 除了关注 type，我们也要关注 extra 显示的结果。

这里说几个重要的参考指标：

* Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错。
* Using temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。

- Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。

**type 字段**就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的**执行效率从低到高的顺序为**：

- All（全表扫描）；
- index（全索引扫描）；
- range（索引范围扫描）；
- ref（非唯一索引扫描）；
- eq_ref（唯一索引扫描）；
- const（结果只有一条的主键或唯一索引扫描）。

在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。

range 表示采用了索引范围扫描，一般在 where 子句中使用 < 、>、in、between 等关键词，只检索给定范围的行，属于范围查找。从这一级别开始，索引的作用会越来越明显，因此**我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式。**

ref 类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀，返回数据返回可能是多条。因为虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使使用索引快速查找到了第一条数据，仍然不能停止，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。

eq_ref 类型是使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。比如，对两张表进行联查，关联条件是两张表的 user_id 相等，且 user_id 是唯一索引，那么使用 EXPLAIN 进行执行计划查看的时候，type 就会显示 eq_ref。

const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id=1。

需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，**const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中**。



### InnoDB数据页结构

数据库的 I/O 操作的最小单位是页，**InnoDB 数据页的默认大小是 16KB**，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。

数据页主要包括以下几个部分：

**文件头、文件尾、用户记录、页目录、最大和最小记录**。

在 文件头 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表。

数据页的主要作用是存储记录，也就是数据库的数据，所以重点说一下数据页中的 用户记录 是怎么组织数据的。

**数据页中的记录按照「主键」顺序组成单向链表**，由于单向链表插入删除效率高 但是检索效率不高，因此，数据页中有一个**页目录**，起到记录的索引作用。

页目录创建的过程如下：

将所有的记录划分成几个组，每组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录；页目录就是 每组**最后一条记录的地址偏移量**，这些地址偏移量会按照先后顺序存储起来。

然后，因为记录是按照「主键值」从小到大排序的，所以**我们通过页目录查找记录时，可以使用二分法快速定位要查询的记录在哪个记录分组，定位到分组后，再遍历组内的所有记录，找到对应的记录**，无需从最小记录开始遍历整个页中的记录链表。



### 数据页内查询流程

数据页内包含了用户记录，每个记录之间用单向链表的方式组织起来，为了加快在数据页内高效查询记录，设计了一个页目录，页目录存储各个槽（也就是分组），且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率。



### 为什么使用B+树作为索引

**B+树是什么**：

B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是**按主键顺序存放**的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。

**优点**：

B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从**千万级的表查询目标数据最多需要 3-4 次磁盘 I/O**，所以B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。

**和其他索引比较：**

**1、B+Tree vs B Tree**

B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。

另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。

**2、B+Tree vs 二叉树**

对于有 N 个叶子节点的 B+Tree，其搜索复杂度为`O(logdN)`，其中 d 表示节点允许的最大子节点个数为 d 个。

在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。

而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 `O(logN)`，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。

**3、B+Tree vs Hash**

Hash 在做等值查询的时候效率很快，搜索复杂度为 O(1)。

但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。

### B+ 树及其查询流程？

 B+ 树的特点：

- 只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。
- 非叶子节点分为不同层次，通过分层来降低每一层的搜索量；
- 所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；

查询流程：

- 从根节点开始，在页内通过二分法快速定位到 页内范围包含查询值 的页
- 在非叶子节点中，继续通过二分法快速定位到 页内范围包含查询值 的页
- 接着，在叶子节点中，通过页目录查找记录时，使用二分法快速定位要查询的记录在哪个记录分组，定位到分组后，再遍历组内的所有记录，找到目标记录。

在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组，最后在分组内进行遍历查找。



### 索引失效情况

- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对索引列使用函数，就会导致索引失效。
- 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。
- MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。



### count(*) count(1) 效率

count(1)、 count(\*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。 所以，如果要执行 count(1)、 count(\*)、 count(主键字段) 时，尽量在数据表上建立二级索引，相比于扫描主键索引效率会高一些。

count(字段)则不会扫描二级索引，因此要避免使用。



## 三、事务

### 事务特性ACID

**原子性**（`Atomicity`）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；

**一致性**（`Consistency`）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；

**隔离性**（`Isolation`）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；

**持久性**（`Durability`）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

**只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！** 

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；







### 脏读、不可重复读、幻读

#### 脏读

**如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。**

假设有两个事务，事务A和事务B，它们都涉及到表中的同一行数据。假设表中的数据是原始的，即没有其他事务在进行操作。

1. 事务A读取了某一行的数据，但尚未提交。
2. 在事务A读取数据的过程中，事务B也读取了同一行的数据。
3. 事务B对读取的数据进行了修改，并将修改后的数据写回到数据库中。
4. 事务A对读取的数据进行了修改，但尚未提交。
5. 事务A回滚操作，即撤销了它的修改。

在这个例子中，**事务B读取了事务A尚未提交的数据，并在修改后提交**。因此，事务B读取的数据是脏的，因为它包含了未提交的事务A的修改。这种脏读可能导致数据的不一致性，因为事务B的修改可能会覆盖事务A的未提交修改。

#### 不可重复读

**在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。**

假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取余额数据，然后继续执行代码逻辑处理，**在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读。**



#### 幻读

##### 定义

**在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。**

假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库查询账户余额大于 100 万的记录，发现共有 5 条，然后事务 B 也按相同的搜索条件也是查询出了 5 条记录。

接下来，事务 A 插入了一条余额超过 100 万的账号，并提交了事务，此时数据库超过 100 万余额的账号个数就变为 6。

然后事务 B 再次查询账户余额大于 100 万的记录，此时查询到的记录数量有 6 条，**发现和前一次读到的记录数量不一样了，就感觉发生了幻觉一样，这种现象就被称为幻读。**



##### 如何解决？

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

##### 为什么没有彻底解决幻读？

举例：

- T1 时刻：事务 A 先执行「快照读语句」：select * from user where id > 100 得到了 3 条记录。
- T2 时刻：事务 B 往**插入**一个 id= 200 的记录并提交；
- T3 时刻：事务 A 再执行「当前读语句」 select * from user where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。

**要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。



### 事务隔离级别

#### 分类

- **读未提交（\*read uncommitted\*）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（\*read committed\*）**，指一个事务提交之后，它做的变更才能被其他事务看到；
- **可重复读（\*repeatable read\*）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（\*serializable\* ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；



- 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
- 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
- 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象，**MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象**；
- 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。



#### 隔离级别如何实现

- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
- 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；
- 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 **Read View 来实现的，它们的区别在于创建 Read View 的时机不同，「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View**。



## MVCC


MVCC的实现方式可以基于以下几个关键组件：

1. 版本号或时间戳：每个数据行都会有一个版本号或时间戳，用于标识该数据行的不同版本。版本号可以是递增的整数，也可以是时间戳。
2. 写操作的版本管理：当一个事务开始执行写操作时，系统会为该事务分配一个唯一的时间戳，并将该事务所做的修改记录为一个新的数据版本。新版本的时间戳等于事务的时间戳。这样可以保留对原始数据的快照，并记录每个事务对数据的修改。
3. 可见性判断：在执行读操作时，系统会根据事务的时间戳和数据行的版本号来判断是否可以看到该数据行。如果数据行的版本号早于事务的时间戳，则数据行对该事务是可见的；否则，该数据行对该事务则不可见。通过版本号和时间戳的比较，实现了事务之间的隔离性。
4. 事务的启动和提交：事务启动时会分配一个唯一的时间戳，该时间戳用于标识该事务的读操作的可见性。当事务提交时，系统会更新事务的状态，并释放该事务所占用的资源。
5. 冲突检测和解决：在执行写操作时，需要检测是否存在其他事务正在并发地修改相同的数据行。如果存在冲突，即其他事务已经提交了新的版本，当前事务需要根据冲突的情况采取相应的策略，如等待或回滚。
6. 回收过期版本：当一个事务提交后，系统会根据需要清理过期的数据版本，以释放存储空间。过期的版本是指那些对于其他事务已经不可见的版本。

**通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）**

#### ReadView字段解析

Read View 有四个重要的字段：

* creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。

- m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，**“活跃事务”指的就是，启动了但还没提交的事务**。
- min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。
- max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1。

id name trx_id ptr

1  a         111    0

1  aa       112    1



#### MVCC实现方式

对于使用 InnoDB 存储引擎的数据库表，它的**聚簇索引记录**中都包含下面**两个隐藏列**：

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。

在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：

- 如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。
- 如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id 值在 Read View 的 min_trx_id max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。
  - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

**这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）**

### 官方定义
InnoDB通过为每一行记录添加两个额外的隐藏的值来实现MVCC， 这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。
但是InnoDB并不存储这些事件发生时的实际时间，相反它只存储这些事件发生时的系统版本号（LSN）。这是一个随着事务的创建而不断增长的数字。每个事务在事务开始时会记录它自己的系统版本号。每个查询必须去检查每行数据的版本号与事务的版本号是否相同。

### 个人理解
MVCC即多版本控制器，其特点就是在同一时间，不同事务可以读取到不同版本的数据，从而去解决脏读和不可重复读的问题

Innodb的MVCC机制就是乐观锁的一种体现，读不加锁，读写不冲突，在不加锁的情况下能让多个事务进行并发读写，并且解决读写冲突问题，极大的提高系统的并发性
### 具体的实现
在数据库的每一行中，添加额外的三个字段：

1. DB_TRX_ID – 记录插入或更新该行的最后一个事务的事务 ID
2. DB_ROLL_PTR – 指向改行对应的 undolog 的指针
3. DB_ROW_ID – 单调递增的行 ID，他就是 AUTO_INCREMENT 的主键 ID

### MVCC解决了哪些问题
1. 脏读：读取其它事务未提交的数据。
2. 不可重复读：一个事务在读取一条数据时，由于另一个事务修改了这条数据并且提交事务，再次读取时导致数据不一致
3. 幻读：一个事务读取了某个范围的数据，同时另一个事务新增了这个范围的数据，再次读取发现俩次得到的结果不一致。
   MVCC在Innodb存储引擎的实现主要是为了提高数据库并发能力，用更好的方式去处理读--写冲突，同时做到不加锁、非阻塞并发读写。

MVCC可以解决脏读，不可重复读，而且MVCC使用快照读解决了部分幻读问题，但是在修改时还是使用当前读，所以还是存在幻读问题，幻读问题最终就是使用间隙锁解决。

### MVCC实现原理
MVCC实现原理是由俩个隐式字段、undolog、Read view来实现的。
#### 隐式字段
在Innodb存储引擎中，在有聚簇索引的情况下每一行记录中都会隐藏俩个字段，如果没有聚簇索引则还有一个6byte的隐藏主键。

俩个隐式字段为DB_TRX_ID,DB_ROLL_PTR，没有聚簇索引还会有DB_ROW_ID这个字段。

* DB_TRX_ID：记录创建这条数据上次修改它的事务 ID
* DB_ROLL_PTR：回滚指针，指向这条记录的上一个版本

隐式字段实际还有一个delete flag字段，即记录被更新或删除，这里的删除并不代表真的删除，而是将这条记录的delete flag改为true

#### undo log（回滚日志）
undo log的作用不只是回滚操作实现原子性，还有另一个作用就是实现MVCC多版本控制器。

undo log细分为两种，insert时产生的undo log、update，delete时产生的undo log

在Innodb中insert产生的undo log在提交事务之后就会被删除，因为新插入的数据没有历史版本，所以无需维护undo log。

update和delete操作产生的undo log都属于一种类型，在事务回滚时需要，而且在快照读时也需要，则需要维护多个版本信息。只有在快照读和事务回滚不涉及该日志时，对应的日志才会被purge线程统一删除。

purge线程会清理undo log的历史版本，同样也会清理del flag标记的记录

#### undo log在mvcc中的作用
undo log保存的是一个版本链，也就是使用DB_ROLL_PTR这个字段来连接的。

当数据库执行一个**select**语句时会产生一致性视图**read view**。

这个read view其实就是在select时所有未提交事务ID组成的数组，数组中最小的事务ID为min_id，已创建的最大事务ID为max_id组成，查询的数据结果需要跟read-view做比较从而得到快照结果。

所以说undo log在mvcc中的作用就是为了根据存储的事务ID和一致性视图做对比，从而得到快照结果。

#### read-view
在执行select时会产生一致性视图，也就是read-view，它是由查询的那一时间所有未提交事务ID组成的数组，和已经创建的最大事务ID组成的。

在这个数组中最小的事务ID被称之为min_id，最大事务ID被称之为max_id，查询的数据结果要根据read-view做对比从而得到快照结果。

于是就产生了以下的对比规则，这个规则就是使用当前的记录的trx_id跟read-view进行对比
#### 版本链对比规则
如果落在trx_id<min_id，表示此版本是已经提交的事务生成的，由于事务已经提交所以数据是可见的

如果落在trx_id>max_id，表示此版本是由将来启动的事务生成的，是肯定不可见的

若在min_id<=trx_id<=max_id时

* 如果row的trx_id在数组中，表示此版本是由还没提交的事务生成的，不可见，但是当前自己的事务是可见的
* 如果row的trx_id不在数组中，表明是提交的事务生成了该版本，可见

**在这里还有一个特殊情况那就是对于已经删除的数据**，在之前的undo log日志讲述时说了update和delete是同一种类型的undo log，同样也可以认为delete就是update的特殊情况。

当删除一条数据时会将版本链上最新的数据复制一份，然后将trx_id修改为删除时的trx_id，同时在该记录的头信息中存在一个delete flag标记，将这个标记写上true，用来表示当前记录已经删除。

在查询时按照版本链的规则查询到对应的记录，如果delete flag标记位为true，意味着数据已经被删除，则不返回数据。


## 四、锁 

在 MySQL 里，根据加锁的范围，可以分为**全局锁、表级锁和行锁**三类。

### 全局锁

全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。

但是，加上全局锁，意味着整个数据库都是只读状态，这样会造成业务停滞。

> 数据库实际上是如何备份的？

实际上，InnoDB是采用 Read View 的方式来进行数据库备份的，在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都可以用这个 Read View。

但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时就要使用全局锁的方法。



**（选择念）**

备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 `–single-transaction` 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。



### 表级锁

MySQL 里面表级别的锁有这几种：

#### 1、表锁

包括共享表锁和独占表，不过在InnoDB中不推荐使用表锁，推荐使用更细粒度的行锁；

#### 2、元数据锁（MDL）

当我们对数据库表进行操作时，会自动给这个表加上 MDL：

- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

MDL 是为了保证当用户对**表**执行 CRUD 操作时，防止其他线程对这个表结构做了变更。



**MDL 可能引发的一些问题（选念）**

因为MDL 是在事务提交后才会释放，也就是 事务执行期间，MDL 是一直持有的。

那如果数据库有一个长事务，那在对表结构做变更操作的时候，可能会发生意想不到的情况，比如下面这个顺序的场景：

1. 首先，线程 A 先启用了长事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；
2. 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
3. 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，

那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，

因为申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。

所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。



#### 3、意向锁

**意向锁的目的是为了快速判断表里是否有记录被加锁**

- 对**某些记录**加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 对**某些纪录**加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。

而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。

意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁和独占表锁发生冲突。



### 行级锁

InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。

在 InnoDB 事务中，对记录加锁的基本单位是 next-key 锁，但是会因为一些条件会退化成间隙锁，或者记录锁。

- Record Lock，记录锁，也就是仅仅把一条记录锁上；
- Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
- Next-Key Lock：记录锁 + 间隙锁 的组合，是**前开后闭区间**，锁定一个范围，并且锁定记录本身。所以，next-key lock 即能保护该记录，又能阻止其他事务将新纪录插入到该间隙中。



#### 行锁加锁情况

记录加锁的基本单位是 next-key  lock，但是在一些场景下会退化成记录锁[)或间隙锁()，**在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁**。

**唯一索引等值查询：**

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**。

**非唯一索引等值查询：**

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。

**非唯一索引和主键索引的范围查询：**

- 唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。

- 非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。



#### next-key lock 潜在问题

关于Next-Key Lock，可能会出现一些问题，比如在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，需要检查语句是否走了索引，**如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了**，每一条更新语句都需要锁住全表，很容易发生事故。

（避免这种事发生的一个方案就是：我们可以将 MySQL 里的 `sql_safe_updates` 参数设置为 1，开启安全更新模式。大致意思为：

update 语句必须满足如下条件之一才能执行成功：

- 使用 where，并且 where 条件中必须有索引列；
- 使用 limit；
- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；

delete 语句必须满足以下条件能执行成功：

- 同时使用 where 和 limit，此时 where 条件中可以没有索引列；）



### 死锁 

#### 发生条件

死锁的四个必要条件：**互斥、占有且等待、不可剥夺、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。

#### 死锁例子？

**举例1：**

可重复读隔离级别下，假设一个订单表 不存在 订单 id>1000 的数据 

此时，有两个事务，分别检查 订单id 为1001 和 1002 的订单是否存在，如果不存在就插入，首先分别执行 select for update 语句，此时，两个事务都拿到 (1000, +无穷] 的 next-key 锁，然后执行 insert 语句时都在等待对方释放 next-key lock，都无法进行插入操作，形成死锁。

**举例2：**

可重复读隔离级别下，假设表中不存在 id 为10 - 20 的数据，

事务 A 和 事务 B 分别 对 id = 12 和 15 的数据进行update，由于不存在，各自加上了(10,20) 的间隙锁，然后分别往表里分别插入 id = 13 ，16 的数据，循环等待，形成死锁。

**举例3**：

一个表，id，a，b，c 字段，id 主键索引，（a,b,c）索引

三个线程同时执行删除同一条数据操作：

delete from table where a=1 and b=1 and c=1;

出现死锁。

**前置知识**：

InnoDB **删除数据加锁情况**：

- 找到满足条件的记录，并且记录有效，则对记录加X锁
- 找到满足条件的记录，但是记录无效(标识为删除的记录)，则对记录加next key 锁
- 未找到满足条件的记录，则对第一个不满足条件的记录加Gap锁，保证没有满足条件的记录插入

**页面锁**：

因为 MySQL 读取或者修改页面，都需要对页面加上读锁或者写锁，页面锁加上之后才能保证页面的内容不会并发修改，因此需要先加页面锁，然后再加上行锁；

**数据库的死锁预防策略**：

死锁预防策略就是为了防止页面锁与事务锁之间产生死锁。InnoDB做了死锁预防的策略：持有事务锁(行锁、表锁)，可以等待获取页面锁；但反之，持有页面锁，不能等待持有事务锁。

**死锁成因**：

1、事务 1 获取页面锁，找到数据，在索引上给记录加行锁，释放页面锁

2、事务 2 也要给记录加锁，获取页面锁，发现记录上锁了，此时释放页面锁进行等待行锁

3、事务 1 删除完成，将记录标记为删除状态，删除记录锁

4、事务 2 获取行锁，此时由于之前释放了页面锁，不能确定数据是否被修改，因此需要重新获取页面锁

5、事务 3 获取页面锁，读取记录发现已经删除了，需要加 next-key lock，但是事务2已经持有了行锁，需要等待，因此释放页面锁，等待 事务2释放行锁

6、事务 2 重新获取了页面锁，发现记录被删除，需要加 next-key lock，但是事务 3 已经在排队等待了，事务 2 持有的行锁又不能兼容 next-key lock，因此需要等待事务 3 释放锁，循环等待发送了。

**解决**：

从业务上解决。



#### 如何避免死锁

死锁的四个必要条件：**互斥、占有且等待、不可强占用、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- **设置事务等待锁的超时时间**。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 `innodb_lock_wait_timeout` 是用来设置超时时间的，默认值时 50 秒。

- **开启主动死锁检测**。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑，默认就开启。

上面这个两种策略是「当有死锁发生时」的避免方式。

我们可以回归业务的角度来预防死锁，对订单做幂等性校验的目的是为了保证不会出现重复的订单，那我们可以直接将 order_no 字段设置为唯一索引列，利用它的唯一性来保证订单表不会出现重复的订单，不过有一点不好的地方就是在我们插入一个已经存在的订单记录时就会抛出异常。



## 五、日志

### undo log

undo log 实现了事务中的**原子性**，主要**用于事务回滚和 MVCC**。

- **实现事务回滚，保障事务的原子性**。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。
- **实现 MVCC（多版本并发控制）关键因素之一**。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。

undo log 记录的内容：

- 在**插入**一条记录时，要把这条记录的主键记下来，这样之后回滚时只需要把这个主键对应的记录**删掉**就好了；
- 在**删除**一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录**插入**到表中就好了；
- 在**更新**一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列**更新为旧值**就好了。



### redo log

redo log 实现了事务中的**持久性**，主要**用于故障恢复**，也就是 crash-safe（崩溃恢复）的能力。

#### WAL技术

说 redo log 之前先说说 **WAL（Write-Ahead Logging**）技术，**WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上**。

由于 MySQL 更新页的时候都是在 内存的 Buffer Pool 中先更新，然后找到合适的机会刷盘，这样提高了读写效率，但是万一断电重启了，内存中还没来得及落盘的脏页数据就会丢失。

为了防止内存数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存，然后将对这个页的修改以 redo log 的形式记录下来，**这个时候更新就算完成了**。

然后，InnoDB 引擎会在适当的时候，由后台线程将内存 Buffer Pool 的脏页刷新到磁盘里。



redo log 是物理日志，记录了某个数据页做了什么修改，比如**对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新**，每当执行一个事务就会产生这样的一条或者多条物理日志。

在事务提交时，只要先将 redo log 持久化到磁盘即可，不需要管内存 Buffer Pool 里的脏页是否持久化。

当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。



redo log 采用的是**顺序写**，磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。也可以说这是 WAL 技术的另外一个优点：**MySQL 的写操作从磁盘的「随机写」变成了「顺序写」**。

而且 redo log 也不是直接写入磁盘的，每当产生一条 redo log 时，会先写入到 redo log buffer，后续再持久化到磁盘



#### redo log 刷盘策略

主要有下面几个时机：

- MySQL 正常关闭时；
- 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；
- InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。
- 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制）。

innodb_flush_log_at_trx_commit 参数：

- 当设置该**参数为 0 时**，在事务提交时不会主动触发写入磁盘的操作。
- 当设置该**参数为 1 时**，每次事务提交 都**将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘**。
- 当设置该**参数为 2 时**，表示每次事务提交时，将缓存在 redo log buffer 里的 redo log 写入到了操作系统的文件缓存。



#### redo log 文件写满怎么办

redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置。

如果 write pos 追上了 checkpoint，就意味着 **redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞**，此时**会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动**，然后 MySQL 恢复正常运行，继续执行新的更新操作。



### binlog

binlog 主要**用于数据备份和主从复制**；

#### 文件格式

binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：

- STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中，主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了now 这种函数，你在主库上执行的结果并不是你在从库执行的结果；
- ROW：记录行数据最终被修改成什么样了，不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
- MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；

#### 为什么有了 binlog， 还要有 redo log？

跟 MySQL 的时间线有关系。

最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。

而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。



#### binlog 刷盘机制

`binlog`的写入时机也非常简单，事务执行过程中，先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到`binlog`文件中。

MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：

- sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；
- sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；
- sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。



#### 主从复制是如何实现的？

具体详细过程如下：

- **主库写入 Binlog**：主库在 提交事务 的请求之后，会先写入 binlog，再提交事务，然后返回给客户端“操作成功”的响应。
- **同步 Binlog**：从库会创建一个专门的 I/O 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 里，再返回给主库“复制成功”的响应。
- **回放 Binlog**：从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后更新存储引擎中的数据，最终实现主从的数据一致性。

在完成主从复制之后，你就可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。



#### 从库是不是越多越好？

不是的。

因为从库数量增加，从库连接上来的 I/O 线程也比较多，**主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽**。

所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。



### 三种日志区别

- **undo log（回滚日志）**：是 Innodb 存储引擎层生成的日志，实现了事务中的**原子性**，主要**用于事务回滚和 MVCC**。
- **redo log（重做日志）**：是 Innodb 存储引擎层生成的日志，实现了事务中的**持久性**，主要**用于掉电等故障恢复**；
- **binlog （归档日志）**：是 Server 层生成的日志，主要**用于数据备份和主从复制**；



**redo log 和 undo log** 是属于 InnoDB 存储引擎的日志，它们的区别在于：

- redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；
- undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；

事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。



**redo log 和 binlog** 区别：

*1、适用对象不同：*

- binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
- redo log 是 Innodb 存储引擎实现的日志；

*2、文件格式不同：*

- binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
  - STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中，主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了now 这种函数，你在主库上执行的结果并不是你在从库执行的结果；
  - ROW：记录行数据最终被修改成什么样了，不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已；
  - MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
- redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；

*3、写入方式不同：*

- binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。
- redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。

*4、用途不同：*

- binlog 用于备份恢复、主从复制；
- redo log 用于掉电等故障恢复。



### 两阶段提交

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现两份日志之间的状态不一致。

#### 过程

当客户端执行 commit 语句或者在自动提交的情况下，MySQL 开启一个内部事务，**分两阶段来完成 XA 事务的提交**：

- **prepare 阶段**：把 内部事务 XID 写入redo log，将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1）；
- **commit 阶段**：把 内部事务 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），然后将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；

#### 异常重启分析

在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID：

- **如果 binlog 中没有当前内部事务的 XID，说明 binlog 还没有刷盘，则回滚事务**。
- **如果 binlog 中有当前内部事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务**。

因此，**对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID**，如果有就提交事务，如果没有就回滚事务。

所以说，**两阶段提交是以 binlog 写成功为事务提交成功的标识**，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。



####  两阶段提交有什么问题？

两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：

- **磁盘 I/O 次数高**：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。
- **锁竞争激烈**：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。

#### 如何解决

**组提交**：

**MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数**，如果说 10 个事务依次排队刷盘的时间成本是 10，那么将这 10 个事务一次性一起刷盘的时间成本则近似于 1。

引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：

- **flush 阶段**：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）；
- **sync 阶段**：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）；
- **commit 阶段**：各个事务按顺序做 InnoDB commit 操作；

上面的**每个阶段都有一个队列**，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。

对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整个过程，可以看的出来，**锁粒度减小了，这样就使得多个阶段可以并发执行，从而提升效率**。



### MySQL 磁盘 I/O 很高，有什么优化的方法？

事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率：

- 设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。
- 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。
- 将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。

## 六、内存

### Buffer Pool 大小

Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 `128MB` 。

可以通过调整 `innodb_buffer_pool_size` 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。

### Buffer Pool 存的内容

MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。

所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，接着将虚拟地址和物理地址建立映射关系。

**Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等**。



### 如何管理空闲页

使用 **空闲链表**，节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址。然后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。



### 如何管理脏页

使用 **Flush 链表**，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。

后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。



### 内存淘汰策略

InnoDB 对 LRU 做了一些优化，LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化：

- 将 LRU 链表 分为**young 和 old 两个区域**，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。
- 当**「页被访问」且「 old 区域停留时间超过 `innodb_old_blocks_time` 阈值（默认为1秒）」**时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。



### 脏页刷盘策略

下面几种情况会触发脏页的刷新：

- 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；
- Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；
- MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；
- MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；

在我们开启了慢 SQL 监控后，如果**「偶尔」出现一些用时稍长的 SQL**，这可能是因为脏页在刷新到磁盘时可能会给数据库带来性能开销，导致数据库操作抖动。

如果间断出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小

## 七、高可用

### MySQL 如何实现高可用的？

1、主库加备库同时部署，如果发生主库故障，随时切换

2、读写分离，也就是主从

3、分库分表 

常见的场景是 一主一备多从



### 主从复制原理

1、主库将数据的操作记录到 binlog 中

2、从库将主库的日志文件拷贝到他的中继日志即配置文件中指定的 relay log 日志文件中，I/O线程去请求主库的 bin-log 日志，并将日志写入到 relay log 中继日志中，此时主库会生成一个log dump线程，用来给从库I/O线程传输bin-log日志文件。

3、从库会读取 relay log，将数据的改变在从库中重新执行一次，将日志文件中的记录变为数据操作行为再次执行，以达到主从数据最终一致性的目的。



### 主备延迟原因

#### 1、备库所在机器的性能要比主库所在的机器性能差

解决方案：对称部署，主从用相同配置的机器

#### 2、备库的压力大。

由于主库直接影响业务，大家使用起来会比较克制，反而忽视了备库的压力控制。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。

解决方法：

1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。

#### 3、大事务

因为主库上必须等事务执行完成才会写入 binlog，再传给备库。

例如：

**一次性地用 delete 语句删除太多数据**：

比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，业务开发人员要一次性地删掉大量历史数据。同时，又因为要避免在高峰期操作会影响业务（至少有这个意识还是很不错的），所以会在晚上执行这些大量数据的删除操作。然后，负责的 DBA 同学半夜就会收到延迟报警。

#### 4、备库并行复制能力（选）

参数 binlog-transaction-dependency-tracking，用来控制是否启用并行复制策略。这个参数的可选值有以下三种。

1. COMMIT_ORDER，表示的就是 根据提交时间顺序 来判断是否可以并行的策略。
2. WRITE SET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。



### 主备切换策略

#### 可靠性优先策略

1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
2. 把主库 A 改成只读状态，即把 readonly 设置为 true；
3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
4. 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
5. 把业务请求切到备库 B。

#### 可用性优先策略

把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。

#### 如何选择

一般是选择可靠性优先策略，但也有极个别例外，例如：

- 有一个库的作用是记录操作日志。这时候，如果数据不一致可以通过 binlog 来修补，而这个短暂的不一致也不会引发业务问题。
- 同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行。









### 基于GTID的主备切换流程

#### GTID

GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它是为了在进行主备切换时候，不要手动选择同步位点，并且确保了每个事务只会执行一遍，避免了主从复制时 出现 插入时唯一键冲突 或者 删除数据时数据不存在 的错误。

它由两部分组成，格式是：GTID= server_uuid : gno

其中：

- server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；
- gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。



每个 MySQL 实例都维护了一个 **GTID 集合**，用来对应 “这个实例执行过的所有事务”。

假设 主：A ，备：A'，从 B C，主库从 A 切换到 A'

从库 B、C、D 只需要分别执行 change master 命令指向实例 A’ 即可切换

然后，实例 B 执行 start slave 命令启动复制进程：

1. 实例 B 指定主库 A’，确定使用 GTID 协议。
2. 实例 B 把 B 的 GTID 集合 set_b 发给主库 A’。
3. 实例 A’ 算出 自己的 GTID 集合 set_a 与 set_b 的差集，从自己的 binlog 文件里面找出第一个不在 set_b 的事务，发给 B；
4. 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。



### 使用 GTID 进行切换的的优点

1、不用手动选择同步位点

2、确保了每个事务只会执行一遍，避免了主从复制时 出现 插入时唯一键冲突 或者 删除数据时数据不存在 的错误。



### 主从延迟原因

其值过大可能由“QPS突增”、“大事务”、“大表DDL”、“锁阻塞”、“表缺少主键或者唯一健”、“低效执行计划”、“硬件资源不足”等因数造成



### 确保主从无延迟 解决方案

主库更新完，在从库上读，可能会出现过期数据，解决方案：

#### 强制走主库方案 

强制走主库方案其实就是，将查询请求做分类。

1. 对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。
2. 对于可以读到旧数据的请求，才将其发到从库上。买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。

#### 判断主从无延迟方案

方案1：

每次从库执行查询请求前，先判断 主从延迟参数seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。

方案2：

判断从库 收到的 GTID集合 与已经执行完毕的 GTID 集合是否相等，但是有可能出现最新的 binlog 没有同步给从库的情况。

方案3：

开启 **半同步复制**，只有当从库也收到 binlog 后才返回事务完成，这样从库和主库的 binlog 就会保存一致，再结合方案2来判断。但是**只适用于一主一从**，如果多了可能就不准确了

方案4：

**等 GTID 方案**

1. trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；
2. 选定一个从库执行查询语句；
3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)（等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；超时返回 1）；
4. 如果返回值是 0，则在这个从库执行查询语句；
5. 否则，到主库执行查询语句。







# Redis

### Redis 和 MySQL 缓存如何保证一致性？

一致性分为：

**强一致性**：它要求系统写入什么，读出来的也会是什么，但实现起来对系统的性能影响大

**弱一致性**：系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态

**最终一致性**：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。例如我的项目中在秒杀场景下使用 redis 扣减完库存后，发送消息队列扣减库存，这样就能保证最终一致性。

这种最终一致性的实现方式又分为是更新数据库的时候更新缓存还是删除缓存 

**更新缓存和删除缓存的区别**：因为更新缓存时在高并发环境下会导致并发写操作产生的竞态条件。即使使用乐观锁或其他机制来确保一致性，仍然无法完全消除数据不一致的可能性。通过删除缓存，可以确保下一次读取时从数据库中获取最新的数据，并避免潜在的并发写冲突。并且当发生数据库事务回滚时，如果缓存中的数据已经被更新，而事务回滚导致数据库中的数据恢复到之前的状态，那么缓存中的数据将与数据库不一致。通过删除缓存，可以确保在事务回滚后，下一次读取将获取到经过回滚的最新数据。所以选用删除缓存的方式。删除缓存又分为先删除redis在更新数据库还是先更新数据库再删除缓存

**先删除redis，再更新数据库的缺点**：可能导致数据库和redis中的数据都是旧数据（删除redis后，再更新数据时失败了）解决方案 延迟双删 写完数据库后，再删除一次。第二次删除缓存，并非立马就删而是等待时间大于读写缓存的时间即可。

**先更新数据库再删除redis 的缺点**：可能导致数据库和redis的数据不一致（redis删除失败）。出错时使用重试机制异步重新处理或者订阅bilog的方式解决。







### 介绍 redis

Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。

Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是**原子性**的，因为执行命令由单线程负责的，不存在并发竞争的问题。

除此之外，Redis 还支持**事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制**等等。



###  为什么用 Redis 作为缓存？

主要是因为 **Redis 具备「高性能」和「高并发」两种特性**。

**1、Redis 具备高性能**

操作 Redis 缓存就是直接操作内存，所以速度相当快。

**2、 Redis 具备高并发**

单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。

所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。



### Redis 除了做缓存，还能做什么？

分布式锁：通过 Redis 来做分布式锁是一种比较常见的方式。通常情况下，我们都是基于 Redisson 来实现分布式锁。
限流：一般是通过 Redis + Lua 脚本的方式来实现限流。
消息队列：Redis 自带的 list 数据结构可以作为一个简单的队列使用。Redis 5.0 中增加的 stream 类型的数据结构更加适合用来做消息队列
延时队列：Redisson 内置了延时队列（基于 sorted set 实现的）。
分布式 Session ：利用 string 或者 hash 保存 Session 数据，所有的服务器都可以访问。



### 说一下 Redis 和 Memcached 的区别和共同点

共同点：都是基于内存的数据库，一般都用来当做缓存使用。都有过期策略。两者的性能都非常高。
区别：
Redis 支持更丰富的数据类型（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。
Memcached 只支持最简单的 k/v 数据类型。
Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。
Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常 。
Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。
Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。
emcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。



### Redis的数据类型以及常见场景 

![img](./MySQL Redis.assets/9fa26a74965efbf0f56b707a03bb9b7f.png)

redis中常用的五种数据结构：string、list、set、zset、hash。

**String**结构底层是 **简单动态字符串（SDS）**，支持扩容，存储字符串。

**list**存储线性有序且可重复的元素，底层数据结构是 **双向链表 和 压缩列表**。目前版本的list由quicklist实现，也就是链表，每个节点由 ziplist 或 listpack 组成

**set**存储无序不可重复的元素，一般用于求交集、差集等，底层数据结构可以是**hash表 或 整数数组**。

**zset**存储的是有序不可重复的元素，zset为每个元素添加了一个score属性作为排序依据，底层数据结构可以是**ziplist 和跳表**。

**hash**类型存储的是键值对，底层数据结构是**ziplist和hash表**。新版本改为listpack和hash



ziplist 组成：

header ： 起始地址、尾元素偏移量（有限）、entry个数

entry：前一个 node 的长度、当前数据类型、数据



与ziplist做对比的话，listpack 牺牲了内存使用率，把删除操作变成设置为空的操作，而不是直接删除，避免了连锁更新的情况。

redis应该是发现极致的内存使用远远不如提高redis的处理性能。由于现在内存比较大，将会是往淡化极致的内存使用率，向更快的方向发力。





后面又支持了四种数据类型：

- BitMap：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO：存储地理位置信息的场景，比如滴滴叫车；
- Stream：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。但是可能会存在丢失数据的情况。



### Redis的线程模型/单线程架构

Redis 采用的是单线程模型，但是 Redis 的单线程最主要指的是 **执行命令是单线程** 的，而Redis 程序并不是单线程的，Redis 会启动多个后台线程来处理 AOF 刷盘、关闭文件、删除 Key 等耗时的操作，而且因为 Redis 的性能瓶颈有时会出现在网络 I/O 上，所以后来也采用了多个 I/O 线程来处理网络请求。

Redis 之所以快，是因为：

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构。（*因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了*）；
- Redis 采用单线程模型可以**避免了多线程之间的竞争**，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，使其能够处理并发请求。*（IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果）*



### AOF 

AOF ：Redis 在执行完一条 写操作 命令后，就会把该命令以追加的方式写入到AOF文件里；

Redis 重启时，会读取该文件中的命令，然后逐一执行命令来进行数据恢复。

#### AOF 刷盘策略

Redis 执行完写操作命令后，会将命令追加到缓冲区，然后调用 write() 把缓冲区数据写入 AOF 文件，此时数据在 内核缓冲区 ，等待内核写入硬盘，何时写入硬盘由配置决定：

- **Always**，它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- **Everysec**，它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。

#### AOF 重写

因为随着执行的写操作命令越来越多，AOF 文件的大小会越来越大。 AOF 文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。

aof文件：

set (a,1)

set (b, 2)

set (a,2)

```java
class Solution {
    public int[] twoSum(int[] nums, int target) {
        int n =nums.length;
        for (int i = 0; i < n; ++i) {
            for (int j = i + 1; j < n; ++j) {
                if (nums[i] + nums[j] == target) {
                    return new int[]{i, j};
                }
            }
        }
        return new int[0];
    }
}
```





所以，Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。

AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

Redis 的 AOF 重写过程是由后台子进程 bgrewriteaof 来完成的，触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。

重写过程中，主进程依然可以正常处理命令，为了解决这种数据不一致问题，Redis 设置了一个 **AOF 重写缓冲区**，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。子进程完成 AOF 重写工作后，主进程将 AOF 重写缓冲区的数据追加到新的 AOF 文件中，然后改名覆盖现有的 AOF 文件。



### RDB

RDB 是将某一时刻的内存数据，以二进制的方式写入磁盘。

因为 AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要全量把日志都执行一遍，一旦 AOF 日志非常多，会造成 Redis 的恢复操作缓慢。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些。

Redis 提供了 save 和 bgsave，他们的区别就在于是否阻塞主线程。



RDB 在生成快照时候，主线程依然是可以接收请求的，使用的是 **写时复制技术（Copy-On-Write, COW）**技术，就是主线程执行写操作时，被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，主线程仍然可以直接修改原来的数据。



### 混合持久化

RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。

AOF 优点是丢失数据少，但是数据恢复不快。

为了集成了两者的优点，提出了混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。

混合持久化是在 AOF 重写过程生效的，先将内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，然后缓冲区命令以 AOF 方式写入到 AOF 文件，写入完成后用新的 AOF 文件替换旧的的 AOF 文件。也就是说，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。



### 过期删除策略

Redis 会把该 key 带上过期时间存储到一个**过期字典**中，查询一个 key 时，Redis 会检查该 key 是否存在于过期字典中。

#### 惰性删除策略

不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。

惰性删除策略的**优点**：

- 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 **CPU 时间最友好**。

惰性删除策略的**缺点**：

- 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的**内存空间浪费**。所以，惰性删除策略对内存不友好。

#### 定期删除策略

每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。

1. 从过期字典中随机抽取 20 个 key；
2. 检查这 20 个 key 是否过期，并删除已过期的 key；
3. 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。

定期删除策略的**优点**：

- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

定期删除策略的**缺点**：

- 难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

#### Redis 主从模式中，对过期键会如何处理？

当 Redis 运行在主从模式下时，**从库不会进行过期扫描，从库对过期的处理是被动的**。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。

从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。



### 内存淘汰策略

分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」

在设置了过期时间的数据中进行淘汰：

- **volatile-random**：随机淘汰设置了过期时间的任意键值；
- **volatile-ttl**：优先淘汰更早过期的键值。
- **volatile-lru**：淘汰所有设置了过期时间的键值中，最久未使用的键值；
- **volatile-lfu**：淘汰所有设置了过期时间的键值中，最少使用的键值；

在所有数据范围内进行淘汰：

- **allkeys-random**：随机淘汰任意键值;
- **allkeys-lru**：淘汰整个键值中最久未使用的键值；
- **allkeys-lfu**：淘汰整个键值中最少使用的键值。



#### Redis 如何实现LRU

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的实现是方式随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。

Redis 对象头中的 lru 字段存储时间戳：

**在 LRU 算法中**，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳

**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 访问时间戳；低 8bit 记录 key 的访问频次。



### 什么是 Redis 事务？

redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。
Redis 可以通过 MULTI，EXEC，DISCARD 和 WATCH 等命令来实现事务功能。
使用MULTI命令来开始一个事务 使用EXEC命令来提交事务
使用WATCH命令监视键，在其他客户端对它们进行修改时取消事务。
使用DISCARD命令来取消事务并清除所有已添加到事务中的命令

## 集群

主从复制：写一定是在主服务器上，然后主服务器同步给从服务器。缺点：当主服务器挂掉的时候，不能自动切换到从服务器上。主从服务器存储数据一样，内存可用性差。
优点：在一定程度上分担主服务器读的压力。
哨兵模式：构建多个哨兵节点监视主从服务器，当主服务器挂掉的时候，自动将对应的从服务器切换成主服务器。优点：实现自动切换，可用性高 。
缺点：主从服务器存储数据一致，内存可用性差。还要额外维护一套哨兵系统，较为麻烦。
集群模式：采用无中心节点的方式实现。多个主服务器相连，一个主服务器可 以有多个从服务器，不同的主服务器存储不同的数据。优点：可用性更高，内存可用性高。

### 主从复制

主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。

连接过程：

1，启动一个从节点，从节点发送一个PSYNC命令，主节点收到后开起一个后台线程生成一份**RDB**文件发送给从节点，从节点收到后先存入磁盘，再加载进内存（全量同步）。 

2，RDB发送完成后，主机点还会发送在生成RDB期间，缓存中新出现的写命令发送给从节点 。

3，当从节点断开并重新连接时主节点会复制期间丢失的数据给从节点（增量同步）。

1 2 3 

### 哨兵

使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。为了解决这个问题，Redis 增加了哨兵模式（**Redis Sentinel**），实现了**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

#### Redis 哨兵集群是通过什么方式组建的？

**哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**。

在主从集群中，主节点上有一个名为 sentinel 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

哨兵把自己的 IP 地址和端口的信息发布到该频道上，如果其他哨兵订阅了该频道。那么此时，其他哨兵就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。

并且哨兵还可以通过 INFO 命令来获取从节点的信息，进而和从节点建立连接。



#### 如何检测节点是否下线？主观下线与客观下线的区别?

Redis Sentinel它通过监控 Redis实例的状态来实现自动故障转移。Redis Sentinel有以下两种方式：
1.主观下线
如果一个 Sentinel 进程在指定时间内没有收到 Redis 实例的 ping 响应，那么它就会将该 Redis 实例标记为主观下线。这个判断是基于 Sentinel 进程本身的主观认定。
2.客观下线
除了主观下线外，Redis Sentinel 还支持客观下线的检测。当多个 Sentinel 进程都认为某个 Redis 实例已经下线时，该 Redis 实例就会被标记为客观下线。一般来说，当超过一半的 Sentinel 进程在指定时间内都认为某个 Redis 实例已经下线时，该 Redis 实例就会被标记为客观下线。

#### 哨兵选举机制

需要选择一个哨兵节点做为 leader 进行故障转移，所以需要选主。

当一个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，

候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。

每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求；当一个哨兵节点收到投票请求时，如果判断主节点主观下线，就把票投给此节点。

如果一个「候选者」满足：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

就能成为 Leader，并向其他节点发送心跳消息，让它们知道新的leader已经产生。



#### 新的主库选择出来后，如何进行故障的转移？

1.主节点失效检测
2.选择新的主节点
3.执行故障转移操作
4.恢复原来的主节点 一旦 Sentinel 检测到原来的主节点已经恢复，它会将原来的主节点重新加入 Redis 集群中，并将其作为新的从节点进行复制。



### 切片集群

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**（Redis Cluster ）方案。

Redis Cluster 主要是为了解决以下问题：
容量限制：单机 Redis 的容量受限于内存大小，如果需要存储更多的数据，就需要使用更多的 Redis 实例，而这样会导致数据分散在多个实例中，管理和维护难度增加。
性能瓶颈：单机 Redis 的性能在处理大规模数据时会受到限制，例如大量的读写请求会导致单机 Redis 的响应速度变慢。
可用性：单机 Redis 面临单点故障问题，如果 Redis 实例出现故障，就会导致整个 Redis 服务不可用。

Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系，**一个切片集群共有 16384（2^14） 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程是这样的：

- 根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
- 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

接下来这些哈希槽会被映射到具体的 Redis 节点上，有两种方案：

- **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
- **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。



### 脑裂

由于网络问题，集群节点之间失去联系，此时主从数据是不同步的；

这时，哨兵也发现主节点失联了，它就认为主节点挂了，重新选举了个主节点，产生两个主服务。

等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。



### 如何解决脑裂

当主节点发现从节点下线的总数量超过阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

在 Redis 的配置文件中有两个参数我们可以设置：

- min-slaves-to-write ，主节点必须要有至少 n 个从节点连接，如果小于这个数，主节点会禁止写数据。
- min-slaves-max-lag ，主从数据复制和同步的延迟不能超过 m 秒，如果超过，主节点会禁止写数据。

举个例子：

假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。

同时，因为原主库卡住了 15s，没有一个从库能和原主库在 10s 内进行数据复制，原主库也无法接收客户端请求了。

这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。



## 场景

### 缓存穿透、击穿、雪崩的区别

缓存穿透：客户端访问不存在的数据，使得请求直达存储层，导致负载过大，直至宕机。原因可能是业务层误删了缓存和库中的数据，或是有人恶意访问不存在的数据。
解决方式：

1.存储层未命中后，返回空值存入缓存层，客户端再次访问时，缓存层直接返回空值。

2.将数据存入布隆过滤器，访问缓存之前经过滤器拦截，若请求的数据不存在则直接返回空值。



缓存击穿：一份热点数据，它的访问量非常大，在它缓存失效的瞬间，大量请求直达存储层，导致服务崩溃。

解决方案：

1.永不过期：对热点数据不设置过期时间。
2.加互斥锁，当一个线程访问该数据时，另一个线程只能等待，这个线程访问之后，缓存中的数据将被重建，届时其他线程就可以从缓存中取值。



缓存雪崩：大量数据同时过期、或是redis节点故障导致服务不可用，缓存层无法提供服务，所有的请求直达存储层，造成数据库宕机。
解决方案：

1.避免数据同时过期，设置随机过期时间。

2.启用降级和熔断措施。

3.设置热点数据永不过期。

4.采用redis集群，一个宕机，另外的还能用

### Redis如何与数据库保持双写一致性

一致性分为：

**强一致性**：它要求系统写入什么，读出来的也会是什么，但实现起来对系统的性能影响大

**弱一致性**：系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态

**最终一致性**：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。例如我的项目中在秒杀场景下使用 redis 扣减完库存后，发送消息队列扣减库存，这样就能保证最终一致性。

这种最终一致性的实现方式又分为是更新数据库的时候更新缓存还是删除缓存 因为更新缓存时在高并发环境下会导致并发写操作产生的竞态条件。即使使用乐观锁或其他机制来确保一致性，仍然无法完全消除数据不一致的可能性。通过删除缓存，可以确保下一次读取时从数据库中获取最新的数据，并避免潜在的并发写冲突。并且当发生数据库事务回滚时，如果缓存中的数据已经被更新，而事务回滚导致数据库中的数据恢复到之前的状态，那么缓存中的数据将与数据库不一致。通过删除缓存，可以确保在事务回滚后，下一次读取将获取到经过回滚的最新数据。所以选用删除缓存的方式。删除缓存又分为先删除redis在更新数据库还是先更新数据库再删除缓存

先删除redis，再更新数据库。缺点：可能导致数据库和redis中的数据都是旧数据（删除redis后，再更新数据时失败了）解决方案 延迟双删 写完数据库后，再删除一次。第二次删除缓存，并非立马就删而是等待时间大于读写缓存的时间即可。然后是先更新数据库再删除redis 。缺点：可能导致数据库和redis的数据不一致（redis删除失败）。出错时使用重试机制异步重新处理或者订阅binlog的方式解决。



### redis常用的缓存读写策略

旁路缓存模式
写:先更新 db 然后直接删除 cache 。
读:从 cache 中读取数据，读取到就直接返回 cache 中读取不到的话，就从 db 中读取数据返回 再把数据放到 cache 中。
读写穿透
服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。
异步缓存写入
异步缓存写入只更新缓存，不直接更新 db，改为异步批量的方式来更新 db。

### redis如何实现一个分布式锁

最简单的一种 加锁：setnx，解锁：del,问题：如果忘记解锁，将会出现死锁。
第二种分布式锁的实现方式：setnx+expire,解锁：del(key).问题：由于setnx和expire的非原子性，当第二步挂掉，仍然会出现死锁。
第三种方式：加锁：将setnx和expire变成原子性操作，set(key,1,30,NX),解锁：del（key）。但是有一种情况比如此时有进程A,如果进程A在任务没有执行完毕时,锁被到期释放了。这种情况下进程A在任务完成后依然会尝试释放锁,因为它的代码逻辑规定它在任务结束后释放锁,但是它的锁早已经被释放过了,那这种情况它释放的就可能是其他线程的锁。为解决这种情况,我们可以在加锁时为key赋一个随机值,来充当进程的标识,进程要记住这个标识。当进程解锁的时候进行判断,是自己持有的锁才能释放,否则不能释放。另外判断,释放这两步需要保持原子性,否则如果第二步失败,就会造成死锁。而获取和删除命令不是原子的,这就需要采用Lua脚本,通过Lua脚本将两个命令编排在一起,而整个Lua脚本的执行是原子的。



### 使用 Redis 实现一个排行榜怎么做？

Redis 中有一个叫做 sorted set 的数据结构经常被用在各种排行榜的场景
相关的一些 Redis 命令: ZRANGE (从小到大排序)、 ZREVRANGE （从大到小排序）、ZREVRANK (指定元素排名)。



### Redis 为什么还有无磁盘复制模式？

Redis 无磁盘复制模式是一种新的主从复制方式，其主要优点是可以减少网络带宽的占用，提高主从同步的速度，同时也减轻了主节点的磁盘负载。
他是将主节点中的数据直接传输给从节点，而需要将数据先写入到磁盘中。主节点不需要生成 RDB 文件或 AOF 文件，因此也不需要进行磁盘的读写操作。



### Redis Cluster 的优势主要包括：

横向扩展：Redis Cluster 可以方便地实现数据的横向扩展，通过增加 Redis 节点的数量，可以增加集群的容量和性能，而无需更改应用程序。
高可用性：Redis Cluster 采用主从复制机制来保证数据的高可用性。当主节点失效时，可以自动切换到从节点，从而避免单点故障问题。
分布式管理：Redis Cluster 可以方便地进行节点的添加、删除和重分片等操作，而无需停止服务。
自动负载均衡：Redis Cluster 可以根据每个节点的负载情况，自动将请求分配到最适合的节点上，从而实现负载均衡。

### Redis Cluster 是如何分片的？

Redis Cluster 使用哈希槽分片策略，将数据按照键名的哈希值映射到一个 0 到 16383 的哈希槽上，然后将每个哈希槽分配到不同的节点上进行存储。

### Redis Cluster 支持重新分配哈希槽吗？

是的，如果遇到新增节点、节点故障、节点扩容等情况，这些变化可能会导致哈希槽的分布不再均匀，进而影响集群的性能和可用性。Redis Cluster 提供了一种叫做“resharding”的机制，可以重新分配哈希槽，使其均匀地分布在新的节点上。

### Redis Cluster 扩容缩容期间可以提供服务吗？

在 Redis Cluster 扩容或缩容期间，集群仍然可以提供服务，但可能会对集群的性能和可用性产生一定的影响。

### Redis Cluster 中的节点是怎么进行通信的？

通过 Gossip 协议进行通信；
